# -*- coding: utf-8 -*-
"""ECG_NB_MAIN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10-r2HYyoJ8Kq4rw2NVmo90TnoWppGEuQ
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Define file paths
file_path1 = '/content/drive/MyDrive/Colab Notebooks/mitbih_train.csv'
file_path2 = '/content/drive/MyDrive/Colab Notebooks/mitbih_test.csv'

# Read the CSV files
mit_train = pd.read_csv(file_path1)
mit_test = pd.read_csv(file_path2)

mit_train

mit_test

# Check the labels in both train and test set
print('train set classes: ', mit_train.iloc[:, -1].unique())
print('test set classes: ', mit_test.iloc[:, -1].unique())

# Change the dtype of the last column to integer
mit_train.iloc[:, -1] = mit_train.iloc[:, -1].astype('int64')
mit_test.iloc[:, -1] = mit_test.iloc[:, -1].astype('int64')

# See the number of each class in train dataset
labels = {
    0: "Normal",
    1: "Artial Premature",
    2: "Premature ventricular contraction",
    3: "Fusion of ventricular and normal",
    4: "Fusion of paced and normal"
}

# Calculate value counts and rename index using the labels dictionary
value_counts = mit_train.iloc[:,-1].value_counts().rename(labels)

pie_fig = px.pie(names=value_counts.index, values=value_counts.values,
                 title="The Percentage of Each Label in The Train Dataset")


pie_fig.update_layout(title_x=0.5, width=800, height=600)
pie_fig.show()

# See the number of each class in test dataset

# Calculate value counts and rename index using the labels dictionary
value_counts = mit_test.iloc[:,-1].value_counts().rename(labels)

pie_fig = px.pie(names=value_counts.index, values=value_counts.values,
                 title="The Percentage of Each Label in The Test Dataset")

pie_fig.update_layout(title_x=0.5, width=800, height=600)
pie_fig.show()

#Resampling the train
from imblearn.over_sampling import RandomOverSampler

data = mit_train.iloc[:, :187]
labels = mit_train.iloc[:, 187]

# Initialize RandomOverSampler
ros = RandomOverSampler(random_state=42)

# Resample the data
data_resampled, labels_resampled = ros.fit_resample(data, labels)

train_df = pd.concat([data_resampled, labels_resampled], axis=1)

train_df.shape

labels = {
    0: "Normal",
    1: "Artial Premature",
    2: "Premature ventricular contraction",
    3: "Fusion of ventricular and normal",
    4: "Fusion of paced and normal"
}

# Calculate value counts and rename index using the labels dictionary
value_counts = train_df.iloc[:,-1].value_counts().rename(labels)


pie_fig = px.pie(names=value_counts.index, values=value_counts.values,
                 title="The Percentage of Each Label After Balancing")


pie_fig.update_layout(title_x=0.5, width=800, height=600)
pie_fig.show()

from sklearn.model_selection import train_test_split

x_train, x_val, y_train, y_val = train_test_split(train_df.iloc[:, :187],
                                                train_df.iloc[:, 187],
                                                test_size= 0.2,
                                                stratify=train_df.iloc[:, 187],
                                                random_state=42)

x_test = mit_test.iloc[:, :187]
y_test = mit_test.iloc[:, 187]

# Select an array of data instead of dataframe
x_train = x_train.values
x_val = x_val.values
x_test = x_test.values

print('x_train shape: ', x_train.shape)
print('y_train shape: ', y_train.shape)
print('x_val shape: ', x_val.shape)
print('y_val shape: ', y_val.shape)
print('x_test shape: ', x_test.shape)
print('y_test shape: ', y_test.shape)

# Reshape datasets to use them in CNN
x_train = x_train.reshape(x_train.shape[0], -1, 1)
x_val = x_val.reshape(x_val.shape[0], -1, 1)
x_test = x_test.reshape(x_test.shape[0], -1, 1)

import tensorflow as tf

# Converts a class vector (integers) to binary class matrix (one hot encoder).

y_train = tf.keras.utils.to_categorical(y_train)

y_val = tf.keras.utils.to_categorical(y_val)

y_test = tf.keras.utils.to_categorical(y_test)

# See some samples of data
print(y_train[-1])
print(y_val[-1])
print(y_test[-1])

# Check the dataset dimensions again
print('x_train shape: ', x_train.shape)
print('y_train shape: ', y_train.shape)
print('x_val shape: ', x_val.shape)
print('y_val shape: ', y_val.shape)
print('x_test shape: ', x_test.shape)
print('y_test shape: ', y_test.shape)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv1D, LSTM, MaxPool1D, Flatten, Dense, BatchNormalization, Input
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau

model_cnn_lstm = Sequential([
    Input(shape=(x_train.shape[1:])),

    Conv1D(64, kernel_size=6, activation='relu'),
    BatchNormalization(),
    MaxPool1D(pool_size=3, strides=2, padding="same"),

    Conv1D(64, kernel_size=3, activation='relu'),
    BatchNormalization(),
    MaxPool1D(pool_size=2, strides=2, padding="same"),

    Conv1D(64, kernel_size=3, activation='relu'),
    BatchNormalization(),
    MaxPool1D(pool_size=2, strides=2, padding="same"),

    LSTM(64, return_sequences=True, activation="tanh"),

    LSTM(32, activation="tanh"),

    Flatten(),

    Dense(64, activation='relu'),
    Dense(32, activation='relu'),
    Dense(5, activation='softmax')
    ])

model_cnn_lstm.summary()

model_cnn_lstm.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])

# Define the file path where the model will be saved
filepath = '/home/sujal/Desktop/RONAN/Wissenstil/best_model_cnn_lstm.keras'

# Set up the callbacks
callbacks = [
    EarlyStopping(monitor='val_loss', patience=8),
    ReduceLROnPlateau(monitor='val_loss', patience=20, min_lr=1e-6, cooldown=20),
    ModelCheckpoint(filepath=filepath, monitor='val_loss', save_best_only=True)
]

history = model_cnn_lstm.fit(x_train, y_train, epochs=10, callbacks=callbacks, batch_size=32, validation_data=(x_val, y_val),verbose=1)

model_cnn_lstm.save("ECGMODEL.h5")

# Plot loss and accuracy of the model
fig, axs = plt.subplots(2, figsize=(10, 10))

# Plot loss
axs[0].plot(history.history['loss'], label='Training Loss')
axs[0].plot(history.history['val_loss'], label='Validation Loss')
axs[0].set_title('Loss Over Epochs')
axs[0].set_xlabel('Epoch')
axs[0].set_ylabel('Loss')
axs[0].legend()
axs[0].grid(True)

# Plot accuracy
axs[1].plot(history.history['accuracy'], label='Training Accuracy')
axs[1].plot(history.history['val_accuracy'], label='Validation Accuracy')
axs[1].set_title('Accuracy Over Epochs')
axs[1].set_xlabel('Epoch')
axs[1].set_ylabel('Accuracy')
axs[1].legend()
axs[1].grid(True)

plt.tight_layout()
plt.show()

# Comprison between the accuracy of model on train and validation datasets
train_score = model_cnn_lstm.evaluate(x_train, y_train)
validation_score = model_cnn_lstm.evaluate(x_val, y_val)

print('Accuracy Train data: ', train_score[1])
print('Accuracy Validation data: ', validation_score[1])

# Predict on the test data
y_pred = model_cnn_lstm.predict(x_test)

from sklearn.metrics import classification_report

# Convert one-hot encoded labels to integer labels
y_test_labels = np.argmax(y_test, axis=1)
y_pred_labels = np.argmax(y_pred, axis=1)

print(classification_report(y_test_labels, y_pred_labels))